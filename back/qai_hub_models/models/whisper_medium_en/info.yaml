name: Whisper-Medium-En
id: whisper_medium_en
status: public
headline: Automatic speech recognition (ASR) model for English transcription as well as translation.
domain: Audio
description: OpenAIâ€™s Whisper ASR (Automatic Speech Recognition) model is a state-of-the-art system designed for transcribing spoken language into written text. It exhibits robust performance in realistic, noisy environments, making it highly reliable for real-world applications. Specifically, it excels in long-form transcription, capable of accurately transcribing audio clips up to 30 seconds long. Time to the first token is the encoder's latency, while time to each additional token is decoder's latency, where we assume a mean decoded length specified below.
use_case: Speech Recognition
tags:
- foundation
applicable_scenarios:
- Smart Home
- Accessibility
related_models:
- whisper_tiny_en
- whisper_base_en
- whisper_small_en
- huggingface_wavlm_base_plus
form_factors:
- Phone
- Tablet
- IoT
- Compute
has_static_banner: true
has_animated_banner: true
dataset: []
technical_details:
  Model checkpoint: medium.en
  Input resolution: 80x3000 (30 seconds audio)
  Mean decoded sequence length: 224 tokens
  Number of parameters: 769 M
  Model size (WhisperEncoder): 769 MB
  Model size (WhisperDecoder): 726 MB
license_type: mit
research_paper: https://cdn.openai.com/papers/whisper.pdf
research_paper_title: Robust Speech Recognition via Large-Scale Weak Supervision
source_repo: https://github.com/openai/whisper/tree/main
license: https://github.com/openai/whisper/blob/main/LICENSE
deploy_license: https://qaihub-public-assets.s3.us-west-2.amazonaws.com/qai-hub-models/Qualcomm+AI+Hub+Proprietary+License.pdf
deploy_license_type: ai-hub-models-license
