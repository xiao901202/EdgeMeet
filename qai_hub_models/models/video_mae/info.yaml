name: Video-MAE
id: video_mae
status: public
headline: Sports and human action recognition in videos.
domain: Computer Vision
description: Video MAE (Masked Auto Encoder) is a network for doing video classification that uses the ViT (Vision Transformer) backbone.
use_case: Video Classification
tags:
- backbone
applicable_scenarios:
- Camera
- Action Recognition
related_models:
- resnet_3d
- resnet_2plus1d
- resnet_mixed
form_factors:
- Phone
- Tablet
has_static_banner: true
has_animated_banner: true
dataset: []
technical_details:
  Model checkpoint: Kinectics-400
  Input resolution: 224x224
  Number of parameters: 87.7M
  Model size: 335 MB
license_type: cc-by-4.0
research_paper: https://arxiv.org/abs/2203.12602
research_paper_title: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training
source_repo: https://github.com/MCG-NJU/VideoMAE
license: https://github.com/MCG-NJU/VideoMAE/blob/main/LICENSE
deploy_license: https://qaihub-public-assets.s3.us-west-2.amazonaws.com/qai-hub-models/Qualcomm+AI+Hub+Proprietary+License.pdf
deploy_license_type: ai-hub-models-license
